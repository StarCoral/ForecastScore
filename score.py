# -*- coding: utf-8 -*-
"""Score.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l68FKBNS2YzpOO9wY7R2cEQvIJMuK2UG
"""

import pandas as pd
import numpy as np
import random as rnd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LogisticRegression

!rm 'test.csv'
!rm 'train.csv'

from google.colab import files
uploaded = files.upload()

train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('testdata.csv')
combine = [train_df,test_df]
train_df.head()
test_df.info()

for x in ["ComputerLanguage","UNIX","calculus","physical","IntroductionComputer"]:
      train_df = train_df[train_df[x].notnull()]
train_df.info()

#train_df["calculus"]=train_df["calculus"].where(train_df["calculus"].notnull(),train_df["calculus"].mean())
#train_df["UNIX"]=train_df["UNIX"].where(train_df["UNIX"].notnull(),train_df["UNIX"].mean())
#train_df["physical"]=train_df["physical"].where(train_df["physical"].notnull(),train_df["physical"].mean())
#train_df["IntroductionComputer"]=train_df["IntroductionComputer"].where(train_df["IntroductionComputer"].notnull(),train_df["IntroductionComputer"].mean())
#train_df["ComputerLanguage"]=train_df["ComputerLanguage"].where(train_df["ComputerLanguage"].notnull(),train_df["ComputerLanguage"].mean())
#train_df.info()

test_df.describe()

test_df["calculus"]=test_df["calculus"].where(test_df["calculus"].notnull(),test_df["calculus"].mean())
test_df["UNIX"]=test_df["UNIX"].where(test_df["UNIX"].notnull(),test_df["UNIX"].mean())
test_df["physical"]=test_df["physical"].where(test_df["physical"].notnull(),test_df["physical"].mean())
test_df["IntroductionComputer"]=test_df["IntroductionComputer"].where(test_df["IntroductionComputer"].notnull(),test_df["IntroductionComputer"].mean())
test_df["ComputerLanguage"]=test_df["ComputerLanguage"].where(test_df["ComputerLanguage"].notnull(),test_df["ComputerLanguage"].mean())

test_df

train_df['ComputerLanguage']=train_df['ComputerLanguage'].astype(float)
train_df['ID']=train_df['ID'].astype(float)
train_df['Highcare']=train_df['Highcare'].astype(float)
test_df['ComputerLanguage']=test_df['ComputerLanguage'].astype(float)
train_df.head()

#查看檔案資料

train_df.info()
print("--------------------------------")
test_df.info()

#將不會使用到的特徵刪除
train_df=train_df.drop(["All","real","ID"],axis=1)
test_df=test_df.drop(["All","real","Highcare"],axis=1)
combine = [train_df,test_df]

#新增特徵:IsChildren  
for dataset in combine:
    dataset["CL"]=9
    dataset.loc[(dataset["ComputerLanguage"] > 10),["CL"]] = 8
    dataset.loc[(dataset["ComputerLanguage"] > 20),["CL"]] = 7
    dataset.loc[(dataset["ComputerLanguage"] > 30),["CL"]] = 6
    dataset.loc[(dataset["ComputerLanguage"] > 40),["CL"]] = 5
    dataset.loc[(dataset["ComputerLanguage"] > 50),["CL"]] = 4
    dataset.loc[(dataset["ComputerLanguage"] > 60),["CL"]] = 3
    dataset.loc[(dataset["ComputerLanguage"] > 70),["CL"]] = 2
    dataset.loc[(dataset["ComputerLanguage"] > 80),["CL"]] = 1
    dataset.loc[(dataset["ComputerLanguage"] > 90),["CL"]] = 0
    dataset["U"]=9
    dataset.loc[dataset["UNIX"] > 10,"U"] = 8
    dataset.loc[dataset["UNIX"] > 20,"U"] = 7
    dataset.loc[dataset["UNIX"] > 30,"U"] = 6
    dataset.loc[dataset["UNIX"] > 40,"U"] = 5
    dataset.loc[dataset["UNIX"] > 50,"U"] = 4
    dataset.loc[dataset["UNIX"] > 60,"U"] = 3
    dataset.loc[dataset["UNIX"] > 70,"U"] = 2
    dataset.loc[dataset["UNIX"] > 80,"U"] = 1
    dataset.loc[dataset["UNIX"] > 90,"U"] = 0
    dataset["CAL"]=9
    dataset.loc[dataset["calculus"] > 10,"CAL"] = 8
    dataset.loc[dataset["calculus"] > 20,"CAL"] = 7
    dataset.loc[dataset["calculus"] > 30,"CAL"] = 6
    dataset.loc[dataset["calculus"] > 40,"CAL"] = 5
    dataset.loc[dataset["calculus"] > 50,"CAL"] = 4
    dataset.loc[dataset["calculus"] > 60,"CAL"] = 3
    dataset.loc[dataset["calculus"] > 70,"CAL"] = 2
    dataset.loc[dataset["calculus"] > 80,"CAL"] = 1
    dataset.loc[dataset["calculus"] > 90,"CAL"] = 0
    dataset["PHY"]=9
    dataset.loc[dataset["physical"] > 10,"PHY"] = 8
    dataset.loc[dataset["physical"] > 20,"PHY"] = 7
    dataset.loc[dataset["physical"] > 30,"PHY"] = 6
    dataset.loc[dataset["physical"] > 40,"PHY"] = 5
    dataset.loc[dataset["physical"] > 50,"PHY"] = 4
    dataset.loc[dataset["physical"] > 60,"PHY"] = 3
    dataset.loc[dataset["physical"] > 70,"PHY"] = 2
    dataset.loc[dataset["physical"] > 80,"PHY"] = 1
    dataset.loc[dataset["physical"] > 90,"PHY"] = 0
    dataset["IC"]=9
    dataset.loc[dataset["IntroductionComputer"] > 10,"IC"] = 8
    dataset.loc[dataset["IntroductionComputer"] > 20,"IC"] = 7
    dataset.loc[dataset["IntroductionComputer"] > 30,"IC"] = 6
    dataset.loc[dataset["IntroductionComputer"] > 40,"IC"] = 5
    dataset.loc[dataset["IntroductionComputer"] > 50,"IC"] = 4
    dataset.loc[dataset["IntroductionComputer"] > 60,"IC"] = 3
    dataset.loc[dataset["IntroductionComputer"] > 70,"IC"] = 2
    dataset.loc[dataset["IntroductionComputer"] > 80,"IC"] = 1
    dataset.loc[dataset["IntroductionComputer"] > 90,"IC"] = 0
train_df.head(69)

#bins=20 間隔20

g = sns.FacetGrid(train_df,col="CL")
g.map(plt.hist,"Highcare",bins=20)

g = sns.FacetGrid(train_df,col="U")
g.map(plt.hist,"Highcare",bins=20)

g = sns.FacetGrid(train_df,col="CAL")
g.map(plt.hist,"Highcare",bins=20)

g = sns.FacetGrid(train_df,col="PHY")
g.map(plt.hist,"Highcare",bins=20)
train_df.head()

g = sns.FacetGrid(train_df,col="IC")
g.map(plt.hist,"Highcare",bins=20)



train_df=train_df.drop(["ComputerLanguage","UNIX","calculus","physical","IntroductionComputer"],axis=1)
test_df=test_df.drop(["ComputerLanguage","UNIX","calculus","physical","IntroductionComputer"],axis=1)
combine = [train_df,test_df]

colormap = plt.cm.RdBu
plt.figure(figsize=(14,12))
plt.title('Score', y=1.05, size=15)
sns.heatmap(train_df.astype(float).corr(),linewidths=0.1,vmax=1.0, 
            square=True, cmap=colormap, linecolor='white', annot=True)

X_train = train_df.drop("Highcare",axis=1)
Y_train = train_df["Highcare"]
X_test = test_df.drop("ID",axis=1).copy()
X_test

from sklearn.naive_bayes import GaussianNB
G=GaussianNB()
G.fit(X_train,Y_train)
Y_pred_g = G.predict(X_test)
acc_g = round(G.score(X_train,Y_train)*100,2)
acc_g

#生成檔案
import time

submission = pd.DataFrame({
        "ID": test_df["ID"],
        "Highcare": Y_pred_g
    })
submission.to_csv('GaussianNB'
                  +".csv", 
                  index=False)
files.download('GaussianNB.csv')